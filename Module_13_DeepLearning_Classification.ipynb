{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Module 13_DeepLearning_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lwallac2/Bank-Marketing/blob/main/Module_13_DeepLearning_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0c5cHd9zEhQ"
      },
      "source": [
        "#**Module 13: Neural Networks and Deep Learning--Classification**\n",
        "In the previous module, you have learned how a Deep Learning Network works and how to build one that will predict one numeric value. \n",
        "\n",
        "**A Deep Neural Network--Regression**\n",
        "<div>\n",
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/shstreuber/Data-Mining/master/images/deepnn_regression.png\" width=\"600\">\n",
        "</div>\n",
        "\n",
        "In this module, we will start with a Deep Learning NN for Classification purposes. Instead of producing ONE numeric value, we will be configuring it to yield categorical output. This means that you'll see as many nodes in the output layer as there are level to your target categories, like the two below.\n",
        "\n",
        "**A Deep Neural Network--Classification**\n",
        "<div>\n",
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/shstreuber/Data-Mining/master/images/deepnn_classification2layers.png\" width=\"600\">\n",
        "</div>\n",
        "\n",
        "At the end of this module, you will be able to:\n",
        "\n",
        "* Configure a deep learning Classification Network \n",
        "* Distinguish the activation functions in the output layer for classifications from those for regression\n",
        "* Apply regular data classification techniques to image classification\n",
        "* Describe the special cases of Convolutional Neural Networks\n",
        "* Solve a simple classification problem\n",
        "\n",
        "To get started, please watch this great video that shows you where we are going with this (and if you don't remember the content from the instructor video any more, please [review that](https://youtu.be/RkiTL_T8VsY), as well):\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "i4D1dLxTysG2",
        "outputId": "cbdb8e1e-43ee-4ea3-d0a6-c3a644938371"
      },
      "source": [
        "from IPython.display import HTML\n",
        "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/vF21cC-8G1U\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/vF21cC-8G1U\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWgxDP65GE8U"
      },
      "source": [
        "##**The Problem**\n",
        "In the previous module, we used a regression Deep Learning network to predict incomeUSD and age. We will start this module with predicting a categorical variable in our adult dataset: Race."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-w4G9TVbfz1H"
      },
      "source": [
        "#**0. Preparation and Setup**\n",
        "You will see that setting up a Deep Learning model for a simple classification is very similar to building a regression model. In fact, the only difference, really, is in the output layer. So, we'll step through the whole development process a bit more quickly than in the previous module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "K9rm7avhgRTH",
        "outputId": "a8f50177-d4e8-4b3e-82ac-ec9ee450ef0c"
      },
      "source": [
        "import tensorflow as tf # This tells Colab that we are using TensorFlow\n",
        "\n",
        "from tensorflow import keras # This is the main TensorFlow library\n",
        "from tensorflow.keras import layers # We are building a Neural Network with several hidden layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "print(\"Current TensorFlow version is\", tf.__version__)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns # for visualization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "np.random.seed(42)\n",
        "\n",
        "#Reading in the data as adult dataframe\n",
        "adult = pd.read_csv(\"https://raw.githubusercontent.com/shstreuber/Data-Mining/master/data/adult.data.simplified.csv\")\n",
        "adult.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current TensorFlow version is 2.8.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age         workclass  education  educationyears       maritalstatus  \\\n",
              "0   39         State-gov  Bachelors              13       Never-married   \n",
              "1   50  Self-emp-not-inc  Bachelors              13  Married-civ-spouse   \n",
              "2   38           Private    HS-grad               9            Divorced   \n",
              "3   53           Private       11th               7  Married-civ-spouse   \n",
              "4   28           Private  Bachelors              13  Married-civ-spouse   \n",
              "\n",
              "          occupation   relationship   race     sex  hoursperweek  \\\n",
              "0       Adm-clerical  Not-in-family  White    Male            40   \n",
              "1    Exec-managerial        Husband  White    Male            13   \n",
              "2  Handlers-cleaners  Not-in-family  White    Male            40   \n",
              "3  Handlers-cleaners        Husband  Black    Male            40   \n",
              "4     Prof-specialty           Wife  Black  Female            40   \n",
              "\n",
              "   nativecountry  incomeUSD  \n",
              "0  United-States      43747  \n",
              "1  United-States      38907  \n",
              "2  United-States      25055  \n",
              "3  United-States      26733  \n",
              "4           Cuba      23429  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e0393dd4-1795-4dbd-82ce-a1bac062f5b2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>education</th>\n",
              "      <th>educationyears</th>\n",
              "      <th>maritalstatus</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>hoursperweek</th>\n",
              "      <th>nativecountry</th>\n",
              "      <th>incomeUSD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>43747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>13</td>\n",
              "      <td>United-States</td>\n",
              "      <td>38907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>25055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>26733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>40</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>23429</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0393dd4-1795-4dbd-82ce-a1bac062f5b2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e0393dd4-1795-4dbd-82ce-a1bac062f5b2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e0393dd4-1795-4dbd-82ce-a1bac062f5b2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LN-Uvoq5gZZ1"
      },
      "source": [
        "#**1. Exploratory Data Analysis**\n",
        "Which is your favorite way of doing this? Practice it below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsNchg3Egg3d"
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP9ThULbghN1"
      },
      "source": [
        "#**2. Preprocessing**\n",
        "No difference here from what we did before; in fact, in the previous model, we already prepared the \"race\" variable for the output layer by one-hot encoding it. Below is a summary of the code with comments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAuzLW3mhcsH"
      },
      "source": [
        "# Downsizing the Dataset to just the numeric attributes\n",
        "adult_dl = pd.DataFrame(adult, columns = ['age', 'educationyears', 'race','hoursperweek','incomeUSD'])\n",
        "\n",
        "# Splitting into Training and Test Set\n",
        "train_dataset = adult_dl.sample(frac=0.8, random_state=0)\n",
        "test_dataset = adult_dl.drop(train_dataset.index)\n",
        "\n",
        "# Splitting Features from Labels\n",
        "train_features = train_dataset.copy()\n",
        "test_features = test_dataset.copy()\n",
        "\n",
        "train_labels = train_features.pop('race')\n",
        "test_labels = test_features.pop('race')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2lu51Mekv6V",
        "outputId": "74322c2b-513f-4594-f903-21697c4c1f00"
      },
      "source": [
        "train_labels.head() # Let's see what the training labels look like now"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22278                 White\n",
              "8950                  White\n",
              "7838                  White\n",
              "16505    Amer-Indian-Eskimo\n",
              "19140                 White\n",
              "Name: race, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbG67ol9keV2"
      },
      "source": [
        "# Encoding the output variable with pd.get_dummies\n",
        "train_labels1 = pd.get_dummies(train_labels, columns=['race'], prefix='', prefix_sep='')\n",
        "test_labels1 = pd.get_dummies(test_labels, columns=['race'], prefix='', prefix_sep='')\n",
        "# Normalizing the input variables\n",
        "normalizer = preprocessing.Normalization(axis=-1)\n",
        "normalizer.adapt(np.array(train_features))\n",
        "normalizer.adapt(np.array(test_features))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "SlM8zPH4h9tf",
        "outputId": "27a8cc82-a3d9-4f83-fbf8-f2f655cc252b"
      },
      "source": [
        "train_labels1.head() # Let's see what the training labels look like encoded"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Amer-Indian-Eskimo  Asian-Pac-Islander  Black  Other  White\n",
              "22278                   0                   0      0      0      1\n",
              "8950                    0                   0      0      0      1\n",
              "7838                    0                   0      0      0      1\n",
              "16505                   1                   0      0      0      0\n",
              "19140                   0                   0      0      0      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bdae16be-f845-4732-89da-a05589b4224a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Amer-Indian-Eskimo</th>\n",
              "      <th>Asian-Pac-Islander</th>\n",
              "      <th>Black</th>\n",
              "      <th>Other</th>\n",
              "      <th>White</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22278</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8950</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7838</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16505</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19140</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bdae16be-f845-4732-89da-a05589b4224a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bdae16be-f845-4732-89da-a05589b4224a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bdae16be-f845-4732-89da-a05589b4224a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inaLuLY-hJxH"
      },
      "source": [
        "#**3. Build the Keras Model**\n",
        "Now, we can build the Sequential model and add layers one at a time until we are happy with our network architecture.\n",
        "\n",
        "* To build the **input layer**, we need to define the number of input features. We use the **input_dim** argument and set it to 4 for the 4 input variables ('age', 'educationyears','hoursperweek','incomeUSD').\n",
        "* The **output layer** will be our race attribute with 5 levels (Amer-Indian-Eskimo,\tAsian-Pac-Islander,\tBlack,\tOther,\tWhite) \n",
        "\n",
        "\n",
        "###**How do we know the number and architecture of layers in the middle?** \n",
        "\n",
        "The short answer is: We don't. The longer answer is: We experiment until we get the best output the fastest. The even longer answer is: We can use various optimization strategies that can help us out somewhat. So, let's assume that trial and error has shown us that three layers is optimal. Furthermore, let's assume that we are going to build a **Dense Network**, aka a **fully connected** network structure, in which every node is connected with every node in the next layer. \n",
        "\n",
        "To define this architecture, we use the Dense class. We will specify the number of neurons or nodes in the layer as the first argument, and set up the activation function with the activation argument.\n",
        "\n",
        "Speaking of **activation function**, we will use the **rectified linear unit** or ReLU activation function on the first two layers and the Softmax function in the output layer (if our output were between 0 and 1, we would use the Sigmoid function). \n",
        "\n",
        "###**Model Design**\n",
        "So, our model looks like this:\n",
        "\n",
        "* The model expects rows of data with 4 variables (the input_dim=4 argument)\n",
        "* The first hidden layer has 12 nodes and uses the relu activation function.\n",
        "* The second hidden layer has 8 nodes and uses the relu activation function.\n",
        "* The output layer has five nodes and uses the Softmax activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sb1mgzo3ubLv",
        "outputId": "0deb164c-d728-48d9-a743-a4f7d0a3fa2e"
      },
      "source": [
        "# define the Keras model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=4, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 12)                60        \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 8)                 104       \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 5)                 45        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 209\n",
            "Trainable params: 209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xY-qTO0r0NVO"
      },
      "source": [
        "#**4. Compile the Keras Model**\n",
        "Now that the model is defined, we can compile it. To do so, we must specify \n",
        "* the **loss function** to use to evaluate a set of weights. In our case, we will use **categorical_crossentropy**.\n",
        "* the **optimizer** searches through different weights for the network and any optional metrics we would like to collect and report during training. In our case, we will define the optimizer as the efficient stochastic gradient descent algorithm “**adam**“. This is a popular version of gradient descent because it automatically tunes itself and gives good results in a wide range of problems.\n",
        "* Finally, because this is a classification problem, we will collect and report the **classification accuracy**, defined via the **metrics** argument."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDnw6qn1z6EO"
      },
      "source": [
        "# compile the Keras model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl1YNORN1mru"
      },
      "source": [
        "#**5. Train the Model**\n",
        "Now that we have defined our model and compiled it, it is time to train the model on some data. We use the fit() function for this purpose. Training occurs over **epochs** and **each epoch is split into batches**.\n",
        "\n",
        "* **Epoch**: One pass through all of the rows in the training dataset. The training process will perform a set number of iterations through the dataset  that we must specify using the 'epochs' argument.\n",
        "\n",
        "* **Batch**: The number of dataset rows that are considered before the model weights are updated within each epoch. One epoch contains one or more batches, based on the defined 'batch_size' argument. \n",
        "\n",
        "For this problem, we will run for a small number of epochs (150) and use a relatively small batch size of 10.\n",
        "\n",
        "###**How do we know the number of epochs and the batch size?**\n",
        "Three words: Trial and error. Again. That's because we will be revising the model until we get the smallest loss function (aka the smallest error). Now, the model will always have **some** error, but the amount of error will level out after some point for a given model configuration. This is called model convergence.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUNgj2mZ3vUl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82955d28-17ff-4798-8e39-b73a1f66c009"
      },
      "source": [
        "model.fit(train_features, train_labels1, epochs=150, batch_size=10)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 305.9008 - accuracy: 0.7373\n",
            "Epoch 2/150\n",
            "2605/2605 [==============================] - 7s 3ms/step - loss: 41.4251 - accuracy: 0.7472\n",
            "Epoch 3/150\n",
            "2605/2605 [==============================] - 6s 2ms/step - loss: 35.5275 - accuracy: 0.7456\n",
            "Epoch 4/150\n",
            "2605/2605 [==============================] - 8s 3ms/step - loss: 37.2926 - accuracy: 0.7437\n",
            "Epoch 5/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 33.6959 - accuracy: 0.7484\n",
            "Epoch 6/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 30.1780 - accuracy: 0.7433\n",
            "Epoch 7/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 28.1085 - accuracy: 0.7463\n",
            "Epoch 8/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 27.9212 - accuracy: 0.7459\n",
            "Epoch 9/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 23.8631 - accuracy: 0.7471\n",
            "Epoch 10/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 18.8852 - accuracy: 0.7489\n",
            "Epoch 11/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 20.0177 - accuracy: 0.7486\n",
            "Epoch 12/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 16.2212 - accuracy: 0.7467\n",
            "Epoch 13/150\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 15.6498 - accuracy: 0.7464\n",
            "Epoch 14/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 13.1032 - accuracy: 0.7444\n",
            "Epoch 15/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 11.4784 - accuracy: 0.7472\n",
            "Epoch 16/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 8.2655 - accuracy: 0.7405\n",
            "Epoch 17/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 3.6518 - accuracy: 0.7504\n",
            "Epoch 18/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 2.6152 - accuracy: 0.7644\n",
            "Epoch 19/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 1.6069 - accuracy: 0.7775\n",
            "Epoch 20/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5899 - accuracy: 0.8536\n",
            "Epoch 21/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5584 - accuracy: 0.8536\n",
            "Epoch 22/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5561 - accuracy: 0.8536\n",
            "Epoch 23/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5559 - accuracy: 0.8536\n",
            "Epoch 24/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 25/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5557 - accuracy: 0.8536\n",
            "Epoch 26/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 27/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 28/150\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 29/150\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 30/150\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 31/150\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 32/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 33/150\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 34/150\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 35/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 36/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 37/150\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 38/150\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 39/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 40/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 41/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 42/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 43/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 44/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 45/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 46/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 47/150\n",
            "2605/2605 [==============================] - 6s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 48/150\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 49/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 50/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 51/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 52/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 53/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 54/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 55/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 56/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 57/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 58/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 59/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 60/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 61/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 62/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5557 - accuracy: 0.8536\n",
            "Epoch 63/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 64/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 65/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 66/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 67/150\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 68/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 69/150\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 70/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 71/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 72/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 73/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 74/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 75/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 76/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 77/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 78/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5557 - accuracy: 0.8536\n",
            "Epoch 79/150\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 80/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5557 - accuracy: 0.8536\n",
            "Epoch 81/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 82/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 83/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 84/150\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 85/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5557 - accuracy: 0.8536\n",
            "Epoch 86/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 87/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 88/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 89/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5557 - accuracy: 0.8536\n",
            "Epoch 90/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 91/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 92/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5557 - accuracy: 0.8536\n",
            "Epoch 93/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 94/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 95/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 96/150\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 97/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 98/150\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 99/150\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 100/150\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 101/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 102/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 103/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 104/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 105/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 106/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 107/150\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 108/150\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 109/150\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 110/150\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5557 - accuracy: 0.8536\n",
            "Epoch 111/150\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 112/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 113/150\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5557 - accuracy: 0.8536\n",
            "Epoch 114/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 115/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 116/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 117/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 118/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 119/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 120/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 121/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 122/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 123/150\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 124/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 125/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 126/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 127/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 128/150\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 129/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 130/150\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 131/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 132/150\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 133/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 134/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 135/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 136/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5557 - accuracy: 0.8536\n",
            "Epoch 137/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 138/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 139/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 140/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 141/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 142/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 143/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 144/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 145/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 146/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 147/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 148/150\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 149/150\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5558 - accuracy: 0.8536\n",
            "Epoch 150/150\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5557 - accuracy: 0.8536\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fad3bb07990>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cd1m1CIV4u9-"
      },
      "source": [
        "#**6. Evaluate the Model**\n",
        "We have trained our neural network and we can now evaluate the performance of the network on the test dataset. To evaluate your model on your training dataset, use the evaluate() function on your model and pass it the test data.\n",
        "\n",
        "This will generate a prediction for each input and output pair and collect scores, including the average loss and any metrics you have configured, such as accuracy.\n",
        "\n",
        "The evaluate() function will return a list with two values. The first will be the loss of the model on the dataset and the second will be the accuracy of the model on the dataset. We are only interested in reporting the accuracy, so we will ignore the loss value."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels1 = pd.get_dummies(test_labels, columns=['race'], prefix='', prefix_sep='')"
      ],
      "metadata": {
        "id": "qJBLr5eNBB_m"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WampDIhW5RpV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1ca4853-c4e0-4b4f-c052-03a9e68d9d67"
      },
      "source": [
        "# evaluate the keras model\n",
        "accuracy = model.evaluate(test_features, test_labels1)\n",
        "print('Accuracy: %.2f' % (accuracy[1]*100))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "204/204 [==============================] - 1s 1ms/step - loss: 1920.3888 - accuracy: 0.8570\n",
            "Accuracy: 85.70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opT9phxWAX6E"
      },
      "source": [
        "#Your Turn\n",
        "As you can tell, steps 5 and 6 above don't work (yet!). This exercise tests your ability to **research** and **debug**. Knowing what you know about running this same network on the same data, but as a regression problem#\n",
        "1. Fix the code in sections 5 and 6 so that the model will run \n",
        "2. Research how to use the predict() function to run the model on the test_features and test_labels. Remember that you will have to encode the test labels in order to use them in the output layer!\n",
        "\n",
        "Use the fields below to work on your code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Leb73W_BbhD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3FOFCIbBbzS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KAQCAxWBb-C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}